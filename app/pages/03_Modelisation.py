import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import seaborn as sns
import matplotlib.pyplot as plt

st.set_page_config(page_title="ModÃ©lisation", layout="wide")
st.title("ğŸ¤– Ã‰tape 3 â€“ EntraÃ®nement, Ã‰valuation et Comparaison des ModÃ¨les")

# === VÃ©rification des donnÃ©es nettoyÃ©es
if "cleaned_df" not in st.session_state:
    st.warning("Veuillez d'abord effectuer le prÃ©traitement.")
    st.stop()

df = st.session_state.cleaned_df.copy()

# === SÃ©paration features / cible
target_col = "classification"
if target_col not in df.columns:
    st.error("La colonne cible 'classification' est manquante.")
    st.stop()

X = df.drop(columns=[target_col])
y = df[target_col]

# Encodage de la cible
if y.dtype == "object":
    y = y.str.strip().str.lower()
    le = LabelEncoder()
    y = le.fit_transform(y)

# One-hot encoding
X = pd.get_dummies(X, drop_first=True)

# === Split train/test
st.subheader("ğŸ“¦ SÃ©paration Train / Test")
test_size = st.slider("Taille du test (%)", min_value=10, max_value=40, value=20, step=5) / 100
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=test_size, random_state=42)

st.write(f"ğŸ“Š X_train shape: {X_train.shape}")
st.write(f"ğŸ“Š X_test shape: {X_test.shape}")
st.write("ğŸ¯ RÃ©partition cible (y_train):")
st.write(pd.Series(y_train).value_counts())

# === DÃ©finition des modÃ¨les
models = {
    "Random Forest": RandomForestClassifier(n_estimators=300, class_weight="balanced", random_state=42),
    "Logistic Regression": LogisticRegression(max_iter=2000, class_weight="balanced", random_state=42),
    "SVM": SVC(kernel="rbf", probability=True, class_weight="balanced", random_state=42),
    "KNN": KNeighborsClassifier(n_neighbors=5)  
}


# === Scoring metrics
scoring = {
    "accuracy": "accuracy",
    "roc_auc": "roc_auc",
    "precision": "precision",
    "recall": "recall",
}

# === EntraÃ®nement et Ã©valuation
if st.button("ğŸš€ Lancer l'entraÃ®nement et la comparaison des modÃ¨les"):
    st.info("En cours...")

    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    results = {}

    for name, model in models.items():
        scores = cross_validate(model, X_train, y_train, scoring=scoring, cv=skf)
        mean_scores = {metric.upper(): np.mean(scores[f'test_{metric}']) for metric in scoring}
        results[name] = mean_scores

    results_df = pd.DataFrame(results).T.round(3)

    st.success("âœ… ModÃ¨les Ã©valuÃ©s avec succÃ¨s")
    st.dataframe(results_df)

    # ğŸ”¥ Meilleur modÃ¨le
    best_model_name = results_df["ROC_AUC"].idxmax()
    best_model = models[best_model_name]
    best_model.fit(X_train, y_train)
    st.session_state.best_model = best_model
    st.session_state.X_test = X_test
    st.session_state.y_test = y_test

    # === ğŸ” Heatmap
    st.subheader("ğŸ“ˆ Comparaison visuelle des modÃ¨les")
    fig, ax = plt.subplots(figsize=(10, 5))
    sns.heatmap(results_df.T, annot=True, fmt=".3f", cmap="Blues", linewidths=0.5, ax=ax)
    ax.set_title("ğŸ“Š Moyennes des mÃ©triques en validation croisÃ©e")
    st.pyplot(fig)

    st.success(f"ğŸ¯ Meilleur modÃ¨le : **{best_model_name}**")

# === ğŸ”® PrÃ©diction sur les donnÃ©es de test
if "best_model" in st.session_state:
    st.subheader("ğŸ”® PrÃ©dictions sur le jeu de test avec le meilleur modÃ¨le")

    best_model = st.session_state.best_model
    X_test = st.session_state.X_test
    y_test = st.session_state.y_test

    y_pred = best_model.predict(X_test)

    results_df = pd.DataFrame({
        "y_test (rÃ©el)": y_test,
        "y_pred (prÃ©dit)": y_pred
    })

    st.write("AperÃ§u des 5 premiÃ¨res prÃ©dictions :")
    st.dataframe(results_df.head())

    # âœ… Matrice de confusion ici (Ã  l'intÃ©rieur du bloc)
    st.subheader("ğŸ§¾ Matrice de Confusion")
    cm = confusion_matrix(y_test, y_pred)
    fig_cm, ax_cm = plt.subplots()
    ConfusionMatrixDisplay(cm).plot(ax=ax_cm, colorbar=False)
    st.pyplot(fig_cm)

else:
    st.info("â„¹ï¸ Veuillez d'abord lancer l'entraÃ®nement pour effectuer des prÃ©dictions.")

