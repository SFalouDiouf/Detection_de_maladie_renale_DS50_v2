# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 02_Pretraitement.py â€“ Pipeline pas-Ã -pas (expanders)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import sys, pathlib, warnings
import streamlit as st
import pandas as pd, numpy as np
from sklearn.impute import SimpleImputer, KNNImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

warnings.filterwarnings("ignore", category=FutureWarning)

st.set_page_config(page_title="ğŸ§¼ PrÃ©-traitement", page_icon="ğŸ§¹", layout="wide")
st.title("ğŸ§¹ Pipeline de PrÃ©-traitement des DonnÃ©es")

# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
# â”‚ 0. RÃ©cupÃ©ration du DataFrame             â”‚
# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
if "uploaded_df" in st.session_state:
    df = st.session_state["uploaded_df"].copy()
elif "clean_df" in st.session_state:
    df = st.session_state["clean_df"].copy()
else:
    st.warning("Veuillez d'abord charger et explorer le fichier.")
    st.stop()

# Nettoyages lÃ©gers (aucune suppression de colonne)
if "id" in df.columns:
    df.drop(columns=["id"], inplace=True)
df.replace("?", np.nan, inplace=True)
for col in ["pcv", "wc", "rc"]:
    if col in df.columns:
        df[col] = pd.to_numeric(df[col], errors="coerce")
if "classification" in df.columns:
    df["classification"] = df["classification"].astype(str).str.strip().str.lower()

numeric_cols   = df.select_dtypes(include=["number"]).columns.tolist()
categoric_cols = df.select_dtypes(exclude=["number"]).drop(columns=["classification"], errors="ignore").columns.tolist()

# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
# â”‚ 1. Analyse des valeurs manquantes        â”‚
# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
with st.expander("ğŸ” Ã‰tape 1 â€“ Analyse des valeurs manquantes", expanded=True):
    st.markdown(
        "Nous commenÃ§ons par **quantifier** les valeurs manquantes afin de "
        "choisir une stratÃ©gie dâ€™imputation adaptÃ©e."
    )
    na_df = (
        df.isna().mean().mul(100).round(1)
        .reset_index().rename(columns={"index": "Colonne", 0: "% NA"})
        .sort_values("% NA", ascending=False)
    )
    st.dataframe(na_df, height=260)
    st.session_state["na_df"] = na_df

# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
# â”‚ 2. Imputation                            â”‚
# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
with st.expander("ğŸ› ï¸ Ã‰tape 2 â€“ Imputation", expanded=False):
    st.markdown(
        """
        **RÃ¨gles fixes basÃ©es sur l'exploration :**  
        â€¢ **â‰¤ 5 % NA** â†’ mÃ©diane (num) ou mode (cat)  
        â€¢ **5 â€“ 40 % NA** â†’ KNN Imputer (k = 3) pour variables numÃ©riques  
        â€¢ **> 40 % NA** â†’ KNN quand mÃªme (on conserve lâ€™info mais on note lâ€™incertitude)
        """
    )
    if st.button("ğŸ” ExÃ©cuter lâ€™imputation"):
        NA_PCT = df.isna().mean().mul(100)
        num_med = [c for c in numeric_cols if NA_PCT[c] <= 5]
        num_knn = [c for c in numeric_cols if NA_PCT[c] > 5]
        cat_all = categoric_cols

        df_imp = df.copy()
        df_imp[num_med] = SimpleImputer(strategy="median").fit_transform(df_imp[num_med])
        if num_knn:
            df_imp[num_knn] = KNNImputer(n_neighbors=3).fit_transform(df_imp[num_knn])
        for c in cat_all:
            df_imp[c] = df_imp[c].fillna(df_imp[c].mode()[0])

        st.session_state["df_imp"] = df_imp
        st.success("Imputation terminÃ©e âœ…")
        st.dataframe(df_imp.head())

# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
# â”‚ 3. Standardisation & encodage            â”‚
# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
with st.expander("âš™ï¸ Ã‰tape 3 â€“ Standardisation & One-Hot Encodage", expanded=False):
    if "df_imp" not in st.session_state:
        st.info("Veuillez d'abord lancer lâ€™imputation.")
    else:
        df_imp = st.session_state["df_imp"]

        # OneHotEncoder : compatibilitÃ© scikit-learn â‰¥1.2
        try:
            ohe = OneHotEncoder(handle_unknown="ignore", sparse_output=False)
        except TypeError:
            ohe = OneHotEncoder(handle_unknown="ignore", sparse=False)

        preprocessor = ColumnTransformer(
            transformers=[
                ("num", Pipeline([
                    ("scaler", StandardScaler())
                ]), numeric_cols),
                ("cat", Pipeline([
                    ("ohe", ohe)
                ]), categoric_cols)
            ]
        )

        if st.button("âš™ï¸ Appliquer Scale + OHE"):
            X = df_imp.drop(columns=["classification"], errors="ignore")
            X_prep = preprocessor.fit_transform(X)

            st.session_state["prep_pipeline"] = preprocessor
            st.session_state["X_prep"] = X_prep

            st.success(f"Transformation effectuÃ©e ! Shape finale : {X_prep.shape}")
            st.write(pd.DataFrame(X_prep[:5]).head())

            st.markdown(
                """
                **Pourquoi ces choix ?**  
                â€¢ `StandardScaler` aligne les Ã©chelles des variables numÃ©riques  
                â€¢ `OneHotEncoder` convertit les catÃ©gorielles, et `handle_unknown="ignore"` Ã©vite les erreurs si une nouvelle modalitÃ© apparaÃ®t en production
                """
            )

# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
# â”‚ 4. RÃ©sumÃ© & passage Ã  la suite           â”‚
# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
with st.expander("âœ… Ã‰tape 4 â€“ RÃ©sumÃ© final", expanded=False):
    if "X_prep" in st.session_state:
        X_prep = st.session_state["X_prep"]
        st.metric("Observations", X_prep.shape[0])
        st.metric("Features finales", X_prep.shape[1])
        st.success("Les donnÃ©es prÃ©parÃ©es et le pipeline sont prÃªts en mÃ©moire !")
        st.markdown(
            "ğŸ‘‰ Ouvrez maintenant la page **ModÃ©lisation** pour entraÃ®ner le modÃ¨le ; "
            "vous y trouverez `prep_pipeline`, `X_prep` et `df_imp` dÃ©jÃ  chargÃ©s."
        )
    else:
        st.info("Terminez lâ€™Ã©tape 3 pour voir ce rÃ©capitulatif.")
